{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial: Training a WSI Classification Model with ABMIL on PANDA Dataset (MIL-Lab)\n",
    "\n",
    "This tutorial trains an attention-based multiple instance learning model on the PANDA (Prostate cANcer graDe Assessment) dataset using pre-extracted UNI v2 features.\n",
    "\n",
    "**Key Difference**: This notebook uses the **MIL-Lab framework** instead of trident's ABMILSlideEncoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A- Dataset Information & Preprocessing\n",
    "\n",
    "- **Dataset**: PANDA (Prostate cANcer graDe Assessment)\n",
    "- **Features**: Pre-extracted UNI v2 features (1536 dimensions)\n",
    "- **Patch size**: 256x256 pixels at 20x magnification\n",
    "- **Task**: Multi-class classification (ISUP grades 0-5)\n",
    "- **Data**:\n",
    "  - WSI directory: `/media/nadim/Data/prostate-cancer-grade-assessment/train_images`\n",
    "  - Features directory: `/media/nadim/Data/prostate-cancer-grade-assessment/panda/`\n",
    "  - Labels CSV: `/media/nadim/Data/prostate-cancer-grade-assessment/train.csv`\n",
    "\n",
    "**Preprocessing Steps**:\n",
    "1. Read slide IDs and labels from CSV\n",
    "2. Scan features directory for available .h5 files\n",
    "3. Match CSV labels with available features\n",
    "4. Perform stratified train/val/test split (70/20/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "IMPROVED DATA PREPROCESSING\n",
      "======================================================================\n",
      "\n",
      "Step 1: Reading labels from CSV...\n",
      "  Found 10616 slides in CSV with labels\n",
      "  Label distribution in CSV:\n",
      "    ISUP 0: 2892\n",
      "    ISUP 1: 2666\n",
      "    ISUP 2: 1343\n",
      "    ISUP 3: 1242\n",
      "    ISUP 4: 1249\n",
      "    ISUP 5: 1224\n",
      "\n",
      "Step 2: Scanning features directory...\n",
      "  Found 10615 feature files\n",
      "\n",
      "Step 3: Matching CSV labels with available features...\n",
      "  Matched: 10615 slides\n",
      "  Missing features: 1 slides\n",
      "\n",
      "  Label distribution after matching:\n",
      "    ISUP 0: 2891\n",
      "    ISUP 1: 2666\n",
      "    ISUP 2: 1343\n",
      "    ISUP 3: 1242\n",
      "    ISUP 4: 1249\n",
      "    ISUP 5: 1224\n",
      "\n",
      "Step 4: Performing stratified split (70% train, 20% val, 10% test)...\n",
      "\n",
      "======================================================================\n",
      "SPLIT SUMMARY\n",
      "======================================================================\n",
      "Total slides: 10615\n",
      "\n",
      "Split distribution:\n",
      "  Train: 7432 (70.0%)\n",
      "  Val:   2121 (20.0%)\n",
      "  Test:  1062 (10.0%)\n",
      "\n",
      "Label distribution per split:\n",
      "\n",
      "TRAIN:\n",
      "  ISUP 0: 2024 ( 27.2%)\n",
      "  ISUP 1: 1866 ( 25.1%)\n",
      "  ISUP 2:  941 ( 12.7%)\n",
      "  ISUP 3:  870 ( 11.7%)\n",
      "  ISUP 4:  874 ( 11.8%)\n",
      "  ISUP 5:  857 ( 11.5%)\n",
      "\n",
      "VAL:\n",
      "  ISUP 0:  578 ( 27.3%)\n",
      "  ISUP 1:  533 ( 25.1%)\n",
      "  ISUP 2:  268 ( 12.6%)\n",
      "  ISUP 3:  248 ( 11.7%)\n",
      "  ISUP 4:  250 ( 11.8%)\n",
      "  ISUP 5:  244 ( 11.5%)\n",
      "\n",
      "TEST:\n",
      "  ISUP 0:  289 ( 27.2%)\n",
      "  ISUP 1:  267 ( 25.1%)\n",
      "  ISUP 2:  134 ( 12.6%)\n",
      "  ISUP 3:  124 ( 11.7%)\n",
      "  ISUP 4:  125 ( 11.8%)\n",
      "  ISUP 5:  123 ( 11.6%)\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slide_id</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b600f26e7bc2daf1917e4078496d37ac</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36531354b9f3353938e4227f7d8a3ece</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e94a11759c86bca9836e27cfd2fb670</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e2b069d3db5dd82610abc684befac2d3</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5289d3ebfc24bbe70206daf1f546b687</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>caaf2645fd3ea43541dad8081e351689</td>\n",
       "      <td>5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42a4d1519445a251149be56ff8d9ed12</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01c977c97e2f5543e65e559d98dec93c</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>369a3711e3d38086b74319999fcf77f5</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5d1abefd41a6663e33995134cbd44838</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           slide_id  label  split\n",
       "0  b600f26e7bc2daf1917e4078496d37ac      2  train\n",
       "1  36531354b9f3353938e4227f7d8a3ece      2  train\n",
       "2  4e94a11759c86bca9836e27cfd2fb670      3  train\n",
       "3  e2b069d3db5dd82610abc684befac2d3      5  train\n",
       "4  5289d3ebfc24bbe70206daf1f546b687      0  train\n",
       "5  caaf2645fd3ea43541dad8081e351689      5  train\n",
       "6  42a4d1519445a251149be56ff8d9ed12      3  train\n",
       "7  01c977c97e2f5543e65e559d98dec93c      3  train\n",
       "8  369a3711e3d38086b74319999fcf77f5      2  train\n",
       "9  5d1abefd41a6663e33995134cbd44838      1  train"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "\n",
    "# Configuration\n",
    "csv_path = '/media/nadim/Data/prostate-cancer-grade-assessment/train.csv'\n",
    "feats_path = '/media/nadim/Data/prostate-cancer-grade-assessment/panda/'\n",
    "SEED = 42\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"IMPROVED DATA PREPROCESSING\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Step 1: Read labels and slide IDs from CSV\n",
    "print(\"Step 1: Reading labels from CSV...\")\n",
    "df_labels = pd.read_csv(csv_path)\n",
    "\n",
    "# Select only necessary columns\n",
    "if 'isup_grade' in df_labels.columns:\n",
    "    df_labels = df_labels[['image_id', 'isup_grade']].rename(columns={'image_id': 'slide_id', 'isup_grade': 'label'})\n",
    "elif 'label' in df_labels.columns:\n",
    "    df_labels = df_labels[['slide_id', 'label']]\n",
    "else:\n",
    "    print(\"ERROR: Could not find label column in CSV\")\n",
    "    \n",
    "print(f\"  Found {len(df_labels)} slides in CSV with labels\")\n",
    "print(f\"  Label distribution in CSV:\")\n",
    "for grade in sorted(df_labels['label'].unique()):\n",
    "    count = len(df_labels[df_labels['label'] == grade])\n",
    "    print(f\"    ISUP {grade}: {count}\")\n",
    "\n",
    "# Step 2: Find all available feature files\n",
    "print(f\"\\nStep 2: Scanning features directory...\")\n",
    "feature_files = glob(os.path.join(feats_path, '*.h5'))\n",
    "available_slide_ids = [os.path.basename(f).replace('.h5', '') for f in feature_files]\n",
    "print(f\"  Found {len(available_slide_ids)} feature files\")\n",
    "\n",
    "# Step 3: Match CSV with available features\n",
    "print(f\"\\nStep 3: Matching CSV labels with available features...\")\n",
    "df_labels['has_features'] = df_labels['slide_id'].isin(available_slide_ids)\n",
    "df_matched = df_labels[df_labels['has_features']].drop(columns=['has_features']).reset_index(drop=True)\n",
    "\n",
    "missing_count = len(df_labels) - len(df_matched)\n",
    "print(f\"  Matched: {len(df_matched)} slides\")\n",
    "print(f\"  Missing features: {missing_count} slides\")\n",
    "\n",
    "print(f\"\\n  Label distribution after matching:\")\n",
    "for grade in sorted(df_matched['label'].unique()):\n",
    "    count = len(df_matched[df_matched['label'] == grade])\n",
    "    print(f\"    ISUP {grade}: {count}\")\n",
    "\n",
    "# Step 4: Perform stratified train/val/test split\n",
    "print(f\"\\nStep 4: Performing stratified split (70% train, 20% val, 10% test)...\")\n",
    "\n",
    "# First split: separate test set (10%)\n",
    "train_val_df, test_df = train_test_split(\n",
    "    df_matched, \n",
    "    test_size=0.10, \n",
    "    stratify=df_matched['label'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Second split: separate train and val from remaining 90% (77.78% train, 22.22% val of remaining)\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=0.222,  # 0.222 * 0.9 ≈ 0.20 of total\n",
    "    stratify=train_val_df['label'],\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# Add split column\n",
    "train_df['split'] = 'train'\n",
    "val_df['split'] = 'val'\n",
    "test_df['split'] = 'test'\n",
    "\n",
    "# Combine back into single dataframe\n",
    "df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SPLIT SUMMARY\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total slides: {len(df)}\\n\")\n",
    "\n",
    "print(\"Split distribution:\")\n",
    "print(f\"  Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Val:   {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nLabel distribution per split:\")\n",
    "for split_name in ['train', 'val', 'test']:\n",
    "    split_df = df[df['split'] == split_name]\n",
    "    print(f\"\\n{split_name.upper()}:\")\n",
    "    for grade in sorted(df['label'].unique()):\n",
    "        count = len(split_df[split_df['label'] == grade])\n",
    "        pct = count / len(split_df) * 100\n",
    "        print(f\"  ISUP {grade}: {count:4d} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\n{'='*70}\\n\")\n",
    "\n",
    "# Display first few rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B- Training an ABMIL Model (using MIL-Lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model parameters: 1184391\n",
      "\n",
      "Train batches: 87\n",
      "Val samples: 798\n",
      "Test samples: 389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nadim/Source/MIL-Lab/MIL-Lab/src/builders/ModelDict.py:193: UserWarning: Pretrained flag is True, but task is set to 'none'. Using random weights\n",
      "  warnings.warn(\"Pretrained flag is True, but task is set to 'none'. Using random weights\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, cohen_kappa_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add MIL-Lab to path if needed\n",
    "# sys.path.insert(0, '/home/nadim/Source/MIL-Lab/MIL-Lab')\n",
    "\n",
    "# Import MIL-Lab model builder\n",
    "from src.builder import create_model\n",
    "\n",
    "# Set deterministic behavior\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Custom dataset for PANDA with UNI v2 features\n",
    "class PANDAH5Dataset(Dataset):\n",
    "    def __init__(self, feats_path, df, split, num_features=512):\n",
    "        self.df = df[df[\"split\"] == split].reset_index(drop=True)\n",
    "        self.feats_path = feats_path\n",
    "        self.num_features = num_features\n",
    "        self.split = split\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        feat_path = os.path.join(self.feats_path, row['slide_id'] + '.h5')\n",
    "        \n",
    "        with h5py.File(feat_path, \"r\") as f:\n",
    "            # UNI v2 features have shape (1, num_patches, 1536)\n",
    "            features = torch.from_numpy(f[\"features\"][:]).squeeze(0)  # Remove batch dimension -> (num_patches, 1536)\n",
    "\n",
    "        # Sample patches for training to control memory\n",
    "        if self.split == 'train':\n",
    "            num_available = features.shape[0]\n",
    "            if num_available >= self.num_features:\n",
    "                indices = torch.randperm(num_available, generator=torch.Generator().manual_seed(SEED))[:self.num_features]\n",
    "            else:\n",
    "                indices = torch.randint(num_available, (self.num_features,), generator=torch.Generator().manual_seed(SEED))\n",
    "            features = features[indices]\n",
    "\n",
    "        label = torch.tensor(row[\"label\"], dtype=torch.long)\n",
    "        return features, label\n",
    "\n",
    "# Initialize MIL-Lab ABMIL model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create ABMIL model using MIL-Lab\n",
    "# Model naming: 'abmil.base.uni_v2.none' means:\n",
    "#   - abmil: model architecture\n",
    "#   - base: configuration (uses default hyperparameters from src/model_configs/abmil/base.yaml)\n",
    "#   - uni_v2: encoder type (automatically sets in_dim=1536)\n",
    "#   - none: no pretrained weights (random initialization)\n",
    "model = create_model(\n",
    "    'abmil.base.uni_v2.none',  # Model specification\n",
    "    num_classes=6,              # 6 ISUP grades (0-5)\n",
    "    dropout=0.2,                # Override default dropout\n",
    "    gate=True                   # Use gated attention\n",
    ").to(device)\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "# Create dataloaders\n",
    "feats_path = '/media/nadim/Data/prostate-cancer-grade-assessment/panda'\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = PANDAH5Dataset(feats_path, df, \"train\")\n",
    "val_dataset = PANDAH5Dataset(feats_path, df, \"val\")\n",
    "test_dataset = PANDAH5Dataset(feats_path, df, \"test\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
    "print(f\"Val samples: {len(val_loader)}\")\n",
    "print(f\"Test samples: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Starting training...\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "\n",
    "# Training loop with validation\n",
    "num_epochs = 5\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Starting training...\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "\n",
    "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
    "        # if FileNotFoundError occurs, skip this batch\n",
    "        \n",
    "        # MIL-Lab models take features directly as [B, M, D] tensor\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # MIL-Lab forward returns (results_dict, log_dict)\n",
    "            results_dict, log_dict = model(features, loss_fn=criterion, label=labels)\n",
    "            loss = results_dict['loss']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "   \n",
    "        # Print progress every 50 batches\n",
    "    if (batch_idx + 1) % 50 == 0:\n",
    "        print(f\"  Epoch [{epoch+1}/{num_epochs}] Batch [{batch_idx+1}/{len(train_loader)}] Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass with MIL-Lab\n",
    "                results_dict, log_dict = model(features, loss_fn=criterion, label=labels)\n",
    "                logits = results_dict['logits']\n",
    "                loss = results_dict['loss']\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_acc = accuracy_score(all_labels, all_preds)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    # Get current learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    old_lr = current_lr\n",
    "    scheduler.step(avg_val_loss)\n",
    "    new_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n",
    "    print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Val Loss:   {avg_val_loss:.4f}\")\n",
    "    print(f\"  Val Acc:    {val_acc:.4f}\")\n",
    "    print(f\"  LR:         {new_lr:.6f}\")\n",
    "    \n",
    "    if new_lr < old_lr:\n",
    "        print(f\"  >>> Learning rate reduced: {old_lr:.6f} -> {new_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_panda_millab.pth')\n",
    "        print(f\"  >>> Saved best model (Val Loss: {best_val_loss:.4f})\")\n",
    "    \n",
    "    print(f\"{'-'*70}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Training complete!\")\n",
    "print(f\"Best validation loss: {best_val_loss:.4f}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(train_losses, label='Train Loss', marker='o')\n",
    "ax1.plot(val_losses, label='Val Loss', marker='s')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss (MIL-Lab)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "ax2.plot(val_accuracies, label='Val Accuracy', marker='o', color='green')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('Validation Accuracy (MIL-Lab)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves_panda_millab.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C- Evaluating the ABMIL Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_model_panda_millab.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Test evaluation\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        \n",
    "        # MIL-Lab forward pass\n",
    "        results_dict, log_dict = model(features)\n",
    "        logits = results_dict['logits']\n",
    "        \n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "test_acc = accuracy_score(all_labels, all_preds)\n",
    "test_balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n",
    "test_kappa = cohen_kappa_score(all_labels, all_preds, weights='quadratic')\n",
    "\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Balanced Accuracy: {test_balanced_acc:.4f}\")\n",
    "print(f\"Test Quadratic Weighted Kappa: {test_kappa:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[f'ISUP {i}' for i in range(6)],\n",
    "            yticklabels=[f'ISUP {i}' for i in range(6)])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix - PANDA Test Set (MIL-Lab)')\n",
    "plt.savefig('confusion_matrix_panda_millab.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Per-class accuracy\n",
    "print(\"\\nPer-class accuracy:\")\n",
    "for i in range(6):\n",
    "    class_acc = cm[i, i] / cm[i].sum() if cm[i].sum() > 0 else 0\n",
    "    print(f\"  ISUP {i}: {class_acc:.4f} ({cm[i, i]}/{int(cm[i].sum())})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D- Generate Attention Heatmap\n",
    "\n",
    "**Note**: This section demonstrates how to extract attention scores from MIL-Lab ABMIL models.\n",
    "\n",
    "**Key Difference from Trident**: \n",
    "- MIL-Lab returns attention in `log_dict['attention']` when `return_attention=True`\n",
    "- Attention has shape `[B, K, M]` where K is number of attention heads (usually 1)\n",
    "- These are raw attention scores before softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Get attention scores for a single slide\n",
    "from PIL import Image\n",
    "\n",
    "# Select a slide from test set\n",
    "test_df = df[df['split'] == 'test']\n",
    "slide_id = test_df.iloc[0]['slide_id']\n",
    "true_label = test_df.iloc[0]['label']\n",
    "\n",
    "print(f\"Processing slide: {slide_id}\")\n",
    "print(f\"True label: ISUP {true_label}\")\n",
    "\n",
    "# Load features\n",
    "feat_path = os.path.join(feats_path, slide_id + '.h5')\n",
    "with h5py.File(feat_path, 'r') as f:\n",
    "    patch_features = torch.from_numpy(f['features'][:]).squeeze(0)  # (num_patches, 1536)\n",
    "    coords = f['coords_patching'][:]\n",
    "    \n",
    "    if hasattr(f['coords_patching'], 'attrs') and 'patch_size' in f['coords_patching'].attrs:\n",
    "        patch_size_level0 = int(f['coords_patching'].attrs['patch_size'])\n",
    "    else:\n",
    "        patch_size_level0 = 256\n",
    "\n",
    "# Ensure coords and features have the same length\n",
    "min_len = min(len(coords), len(patch_features))\n",
    "coords = coords[:min_len]\n",
    "patch_features = patch_features[:min_len]\n",
    "\n",
    "print(f\"Loaded {len(coords)} patches\")\n",
    "\n",
    "# Get attention scores using MIL-Lab\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    features = patch_features.float().to(device).unsqueeze(0)  # Add batch dimension: [1, M, D]\n",
    "    \n",
    "    # Request attention scores in log_dict\n",
    "    results_dict, log_dict = model(features, return_attention=True)\n",
    "    \n",
    "    logits = results_dict['logits']\n",
    "    attention = log_dict['attention']  # Shape: [B, K, M]\n",
    "\n",
    "predicted_class = torch.argmax(logits, dim=1).item()\n",
    "attention_scores = attention.cpu().numpy().squeeze()  # Remove batch and head dimensions: [M]\n",
    "\n",
    "# Ensure attention scores match coords length\n",
    "attention_scores = attention_scores[:len(coords)]\n",
    "\n",
    "print(f\"Predicted: ISUP {predicted_class}\")\n",
    "print(f\"Attention range: [{attention_scores.min():.4f}, {attention_scores.max():.4f}]\")\n",
    "print(f\"Attention shape: {attention_scores.shape}\")\n",
    "\n",
    "# Optional: If you have trident installed, you can visualize the heatmap\n",
    "try:\n",
    "    from trident import load_wsi, visualize_heatmap\n",
    "    \n",
    "    slide_path = f'/media/nadim/Data/prostate-cancer-grade-assessment/train_images/{slide_id}.tiff'\n",
    "    \n",
    "    if os.path.exists(slide_path):\n",
    "        job_dir = './heatmap_output_panda_millab'\n",
    "        os.makedirs(job_dir, exist_ok=True)\n",
    "        \n",
    "        slide = load_wsi(slide_path=slide_path, lazy_init=False)\n",
    "        \n",
    "        # Generate heatmap with jet colormap\n",
    "        heatmap_save_path = visualize_heatmap(\n",
    "            wsi=slide,\n",
    "            scores=attention_scores,\n",
    "            coords=coords,\n",
    "            vis_level=1,\n",
    "            patch_size_level0=patch_size_level0,\n",
    "            normalize=True,\n",
    "            num_top_patches_to_save=0,\n",
    "            output_dir=job_dir,\n",
    "            cmap='jet',\n",
    "            filename=f'{slide_id}_ISUP{true_label}_heatmap_millab.png'\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nHeatmap saved to: {heatmap_save_path}\")\n",
    "        \n",
    "        # Display heatmap\n",
    "        heatmap_img = Image.open(heatmap_save_path)\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        plt.imshow(heatmap_img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Attention Heatmap (MIL-Lab)\\nSlide: {slide_id} | True: ISUP {true_label} | Predicted: ISUP {predicted_class}',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"\\nSlide not found at {slide_path}\")\n",
    "        print(\"Attention scores extracted successfully. Install trident to visualize heatmaps.\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"\\nTrident not installed. Attention scores extracted successfully.\")\n",
    "    print(\"To visualize heatmaps, install trident: pip install trident\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E- Heatmap Visualization (Trident-Compatible)\n",
    "\n",
    "**Important**: Since the patches were extracted using **Trident**, we use the Trident-compatible visualizer.\n",
    "\n",
    "**Key Features:**\n",
    "- **Works with Trident coordinates** - No coordinate mismatch issues\n",
    "- **Rank-based Normalization** - Same as Trident's approach\n",
    "- **Alpha Blending** - Smooth overlay on original H&E image\n",
    "- **Top-K Patch Sampling** - Automatically saves patches with highest attention\n",
    "- **Multiple Colormaps** - Support for jet, coolwarm, viridis, etc.\n",
    "\n",
    "**Why Not CLAM-style?** CLAM does tissue segmentation at visualization time, which doesn't align with Trident's patch coordinates. Trident does tissue masking during extraction, so we just overlay on the full image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Trident-compatible visualizer\n",
    "from src.visualization import TridentVisualizer\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "# Visualize examples from different ISUP grades\n",
    "test_df = df[df['split'] == 'test']\n",
    "\n",
    "# Get one example from each ISUP grade (0-5)\n",
    "example_slides = []\n",
    "for grade in range(6):\n",
    "    grade_slides = test_df[test_df['label'] == grade]\n",
    "    if len(grade_slides) > 0:\n",
    "        example_slides.append(grade_slides.iloc[0])\n",
    "    else:\n",
    "        print(f\"Warning: No test slides found for ISUP grade {grade}\")\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Visualizing {len(example_slides)} slides from different ISUP grades\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = './heatmap_output_trident_style'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Visualize each example\n",
    "num_examples = len(example_slides)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, slide_row in enumerate(example_slides):\n",
    "    slide_id = slide_row['slide_id']\n",
    "    true_label = slide_row['label']\n",
    "    \n",
    "    print(f\"Processing slide {idx+1}/{num_examples}: {slide_id} (ISUP {true_label})\")\n",
    "    \n",
    "    # Load features and coordinates\n",
    "    feat_path = os.path.join(feats_path, slide_id + '.h5')\n",
    "    slide_path = f'/media/nadim/Data/prostate-cancer-grade-assessment/train_images/{slide_id}.tiff'\n",
    "    \n",
    "    with h5py.File(feat_path, 'r') as f:\n",
    "        patch_features = torch.from_numpy(f['features'][:]).squeeze(0)\n",
    "        coords = f['coords_patching'][:]\n",
    "        \n",
    "        if hasattr(f['coords_patching'], 'attrs') and 'patch_size' in f['coords_patching'].attrs:\n",
    "            patch_size_level0 = int(f['coords_patching'].attrs['patch_size'])\n",
    "        else:\n",
    "            patch_size_level0 = 256\n",
    "    \n",
    "    # Ensure matching lengths\n",
    "    min_len = min(len(coords), len(patch_features))\n",
    "    coords = coords[:min_len]\n",
    "    patch_features = patch_features[:min_len]\n",
    "    \n",
    "    # Get attention scores\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        features_input = patch_features.float().to(device).unsqueeze(0)\n",
    "        results_dict, log_dict = model(features_input, return_attention=True)\n",
    "        attention_scores = log_dict['attention'].cpu().numpy().squeeze()[:len(coords)]\n",
    "        predicted_class = torch.argmax(results_dict['logits'], dim=1).item()\n",
    "    \n",
    "    # Initialize visualizer\n",
    "    viz = TridentVisualizer(model, wsi_path=slide_path)\n",
    "    \n",
    "    # Create heatmap\n",
    "    heatmap = viz.create_heatmap(\n",
    "        features=patch_features,\n",
    "        coords=coords,\n",
    "        attention_scores=attention_scores,\n",
    "        patch_size_level0=patch_size_level0,\n",
    "        vis_level=-1,\n",
    "        cmap='jet',\n",
    "        alpha=0.4,\n",
    "        normalize=True,\n",
    "        output_path=os.path.join(output_dir, f'{slide_id}_ISUP{true_label}_pred{predicted_class}.png')\n",
    "    )\n",
    "    \n",
    "    # Display heatmap with colorbar\n",
    "    im = axes[idx].imshow(heatmap)\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Add colorbar\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    divider = make_axes_locatable(axes[idx])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = plt.colorbar(ScalarMappable(norm=Normalize(vmin=0, vmax=1), cmap='jet'), cax=cax)\n",
    "    cbar.set_label('Attention Score', rotation=270, labelpad=15)\n",
    "    \n",
    "    # Title with true and predicted labels\n",
    "    title_color = 'green' if predicted_class == true_label else 'red'\n",
    "    axes[idx].set_title(\n",
    "        f'ISUP {true_label} → Pred: {predicted_class}\\nSlide: {slide_id}',\n",
    "        fontsize=12, fontweight='bold', color=title_color, pad=10\n",
    "    )\n",
    "    \n",
    "    print(f\"  Attention range: [{attention_scores.min():.4f}, {attention_scores.max():.4f}]\")\n",
    "    print(f\"  Predicted: ISUP {predicted_class}\\n\")\n",
    "\n",
    "# Hide unused subplots if less than 6 grades available\n",
    "for idx in range(len(example_slides), 6):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle(\n",
    "    'ABMIL Attention Heatmaps - One Example per ISUP Grade',\n",
    "    fontsize=18, fontweight='bold', y=0.995\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'all_grades_comparison.png'), dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Visualization Complete!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"- Individual heatmaps saved for each grade\")\n",
    "print(f\"- Comparison grid: all_grades_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different colormaps for the same slide\n",
    "print(\"Comparing different colormaps...\\n\")\n",
    "\n",
    "# Use the first example slide\n",
    "slide_row = example_slides[0]\n",
    "slide_id = slide_row['slide_id']\n",
    "true_label = slide_row['label']\n",
    "\n",
    "# Load features\n",
    "feat_path = os.path.join(feats_path, slide_id + '.h5')\n",
    "slide_path = f'/media/nadim/Data/prostate-cancer-grade-assessment/train_images/{slide_id}.tiff'\n",
    "\n",
    "with h5py.File(feat_path, 'r') as f:\n",
    "    patch_features = torch.from_numpy(f['features'][:]).squeeze(0)\n",
    "    coords = f['coords_patching'][:]\n",
    "    patch_size_level0 = 256\n",
    "\n",
    "min_len = min(len(coords), len(patch_features))\n",
    "coords = coords[:min_len]\n",
    "patch_features = patch_features[:min_len]\n",
    "\n",
    "# Get attention scores\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    features_input = patch_features.float().to(device).unsqueeze(0)\n",
    "    results_dict, log_dict = model(features_input, return_attention=True)\n",
    "    attention_scores = log_dict['attention'].cpu().numpy().squeeze()[:len(coords)]\n",
    "    predicted_class = torch.argmax(results_dict['logits'], dim=1).item()\n",
    "\n",
    "# Initialize visualizer\n",
    "viz = TridentVisualizer(model, wsi_path=slide_path)\n",
    "\n",
    "# Different colormap options\n",
    "cmaps = [\n",
    "    ('jet', 'Jet (Rainbow)'),\n",
    "    ('coolwarm', 'Coolwarm (Diverging)'),\n",
    "    ('hot', 'Hot (Sequential)'),\n",
    "    ('viridis', 'Viridis (Perceptual)')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (cmap_name, cmap_label) in enumerate(cmaps):\n",
    "    print(f\"Creating heatmap with {cmap_label}...\")\n",
    "    \n",
    "    heatmap = viz.create_heatmap(\n",
    "        features=patch_features,\n",
    "        coords=coords,\n",
    "        attention_scores=attention_scores,\n",
    "        patch_size_level0=patch_size_level0,\n",
    "        vis_level=-1,\n",
    "        cmap=cmap_name,\n",
    "        alpha=0.4,\n",
    "        normalize=True\n",
    "    )\n",
    "    \n",
    "    # Display heatmap\n",
    "    im = axes[idx].imshow(heatmap)\n",
    "    axes[idx].axis('off')\n",
    "    \n",
    "    # Add colorbar\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "    divider = make_axes_locatable(axes[idx])\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = plt.colorbar(ScalarMappable(norm=Normalize(vmin=0, vmax=1), cmap=cmap_name), cax=cax)\n",
    "    cbar.set_label('Attention', rotation=270, labelpad=15)\n",
    "    \n",
    "    axes[idx].set_title(cmap_label, fontsize=14, fontweight='bold', pad=10)\n",
    "\n",
    "plt.suptitle(\n",
    "    f'Colormap Comparison - {slide_id} (ISUP {true_label} → Pred: {predicted_class})',\n",
    "    fontsize=18, fontweight='bold', y=0.995\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, f'{slide_id}_colormap_comparison.png'), dpi=200, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nColormap comparison complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Differences: MIL-Lab vs Trident\n",
    "\n",
    "### Model Creation\n",
    "**Trident**:\n",
    "```python\n",
    "from trident.slide_encoder_models import ABMILSlideEncoder\n",
    "model = MultiClassABMILModel(input_feature_dim=1536, n_classes=6)\n",
    "```\n",
    "\n",
    "**MIL-Lab**:\n",
    "```python\n",
    "from src.builder import create_model\n",
    "model = create_model('abmil.base.uni_v2.none', num_classes=6)\n",
    "```\n",
    "\n",
    "### Forward Pass\n",
    "**Trident**:\n",
    "```python\n",
    "features_dict = {'features': features.to(device)}\n",
    "outputs = model(features_dict)\n",
    "```\n",
    "\n",
    "**MIL-Lab**:\n",
    "```python\n",
    "features = features.to(device)  # Direct tensor, no dict wrapper\n",
    "results_dict, log_dict = model(features, loss_fn=criterion, label=labels)\n",
    "logits = results_dict['logits']\n",
    "loss = results_dict['loss']\n",
    "```\n",
    "\n",
    "### Attention Retrieval\n",
    "**Trident**:\n",
    "```python\n",
    "logits, attention = model(features_dict, return_raw_attention=True)\n",
    "```\n",
    "\n",
    "**MIL-Lab**:\n",
    "```python\n",
    "results_dict, log_dict = model(features, return_attention=True)\n",
    "attention = log_dict['attention']  # Shape: [B, K, M]\n",
    "```\n",
    "\n",
    "### Visualization (IMPORTANT!)\n",
    "\n",
    "**Trident**:\n",
    "```python\n",
    "from trident import visualize_heatmap\n",
    "heatmap_path = visualize_heatmap(wsi=wsi, scores=scores, coords=coords, ...)\n",
    "```\n",
    "\n",
    "**MIL-Lab (Trident-Compatible)**:\n",
    "```python\n",
    "from src.visualization import TridentVisualizer\n",
    "viz = TridentVisualizer(model, wsi_path=slide_path)\n",
    "heatmap = viz.create_heatmap(features=features, coords=coords, ...)\n",
    "```\n",
    "\n",
    "**Why Trident-Compatible?** Since patches were extracted using Trident, the coordinates are Trident's. MIL-Lab provides a Trident-compatible visualizer that works with these coordinates without tissue segmentation mismatches.\n",
    "\n",
    "### Advantages of MIL-Lab\n",
    "1. **Standardized interface** across all MIL models (ABMIL, TransMIL, CLAM, etc.)\n",
    "2. **Easy model switching**: Change `'abmil'` to `'transmil'`, `'clam'`, `'dsmil'`, etc.\n",
    "3. **Pretrained weights**: Load `'abmil.base.uni_v2.pc108-24k'` for transfer learning\n",
    "4. **Encoder flexibility**: Automatically handles different feature dimensions (UNI, UNIv2, CONCH, etc.)\n",
    "5. **HuggingFace integration**: Compatible with transformers library\n",
    "6. **Dual visualization**: Both Trident-compatible and CLAM-style visualizers available"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mil2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
